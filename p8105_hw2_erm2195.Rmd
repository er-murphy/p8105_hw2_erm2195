---
title: "P8105 Homework 2"
output: github_document
date: "2023-10-02"
---

# Problem 1
Goal: merging the FiveThirtyEight `pols-month.csv`, `unemployment.csv`, and `snp.csv` data into a single data frame using year and month as keys across datasets.

## Loading Libraries
First, loading the `tidyverse` and `readxl` libraries for use throughout the homework:

```{r library}
library(tidyverse)
library(readxl)
```

## Cleaning `pols-month` Data
Now, cleaning the data in `pols-month.csv`:

* Using separate() to break up the variable `mon` into integer variables `year`, `month`, and `day`
* Replacing month number with month name
* Creating a `president` variable taking values "gop" and "dem"
* Removing `prez_dem` and `prez_gop` variables
* Removing the `day` variable

```{r cleaning_pols}

pols = 
  read_csv("Data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-") |> 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day),
    president = if_else(prez_dem != 0 , "dem", "gop"),
    month = case_match(month,
      1 ~ "January",
      2 ~ "February",
      3 ~ "March",
      4 ~ "April",
      5 ~ "May",
      6 ~ "June",
      7 ~ "July",
      8 ~ "August",
      9 ~ "September",
      10 ~ "October",
      11 ~ "November",
      12 ~ "December")
  ) |> 
  select(-starts_with("prez"), -day)

```

## Cleaning `snp` Data
Second, cleaning the data in `snp.csv` using a similar process:

* Using separate() to break up the variable `date` into integer variables `year`, `month`, and `day`
* Converting the `year` variable into a 4 digit value
* Replacing month number with month name
* Reorganizing so that year and month are the leading columns
* Removing the `day` variable

```{r cleaning_snp}
snp = 
  read_csv("Data/snp.csv") |> 
  janitor::clean_names() |> 
  separate(date, into = c("month", "day", "year"), sep = "/") |> 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day),
    year = if_else(as.integer(year) < 24, as.integer(year) + 2000, as.integer(year) + 1900),
    month = case_match(month,
      1 ~ "January",
      2 ~ "February",
      3 ~ "March",
      4 ~ "April",
      5 ~ "May",
      6 ~ "June",
      7 ~ "July",
      8 ~ "August",
      9 ~ "September",
      10 ~ "October",
      11 ~ "November",
      12 ~ "December")
  ) |> 
  select(year, month, close)

```

## Cleaning `unemployment` Data
Third, tidying the data in `unemployment.csv` so that it can be merged with the other two datasets:

* Switch from "wide" to "long" format - turn months into a single column, and the value of existing `months` column into a column called `unemployment`
* Converting month names to capitalized full names to match the format of other datasets

```{r cleaning_unemployment}
unemployment = 
  read_csv("Data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(jan:dec, names_to = "month", values_to = "unemployment") |> 
  mutate(
    month = case_match(month,
    "jan" ~ "January",
    "feb" ~ "February",
    "mar" ~ "March",
    "apr" ~ "April",
    "may" ~ "May",
    "jun" ~ "June",
    "jul" ~ "July",
    "aug" ~ "August",
    "sep" ~ "September",
    "oct" ~ "October",
    "nov" ~ "November",
    "dec" ~ "December")
  )
```

## Merging the Data Sets
Joining the datasets by merging `snp` into `pols`, and then merging `unemployment` into the result. The resulting dataset is called `data_538`.

```{r merging_pols_snp_unemployment}

data_538 = left_join(pols, snp) |> 
  left_join(x = _, y = unemployment)

str(data_538)
```

## Description of the Combined Data Set
The `pols` data set has `r nrow(pols)` observations and `r ncol(pols)` variables. It details the party affiliation distribution (democrat or republican) for governors and senators in a given year from `r pols |> pull(year) |> min()` to `r pols |> pull(year) |> max()`. It also specifies the political party of the president at that time. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, and contains the closing value of the S&P index on the associated date. The included dates range from `r snp |> pull(year) |> min()` to `r snp |> pull(year) |> max()`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables, and contains the percentage of unemployment on the associated date, ranging from years `r unemployment |> pull(year) |> min()` to `r unemployment |> pull(year) |> max()`. 

From the merged `538_data` data set we can see that in January from 1975 onward, in years with a democratic president, the average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`. For comparison, the average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.


# Problem 2

## Cleaning `Mr. Trash Wheel` Data
First, reading in and cleaning the data from the Excel file sheet `Mr. Trash Wheel`:

* Specifying the sheet in the Excel file
* Using arguments in `read_excel`, omitting the first row and `Homes` column, given that they contain notes and Excel-based functions
* Removing the last row, which is a sum count of column values and not dumpster-specific data, as well as any rows with no value for the `dumpster` value
* Converting the year variable to be of numeric type, to better match with the other two datasets coming up
* Fixing an issue where one row specifies a month and year of January 2020, but the associated date is 1/20/1900 rather than 1/20/2020
* Creating a `homes_powered` for the approximate number of homes powered, based on the calculation described in the Homes powered note. Rounding this a whole number, which makes more intuitive sense than powering 0.27 of a home
* Rounding the `sports_balls` column so that it's in whole numbers like the other trash count variables

Note: Rather than specifying the columns to import in the read_excel statement, I think it makes more sense to import them all and then just drop the Homes column specifically. That way, this code will still work if additional columns are added in future years. But, doing it this way as it seems like the right call, given that the question specified that we should omit columns with non-data entries within the arguments of `read_excel`.

```{r cleaning_mister}
mister = 
  read_excel("Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:M"), skip = 1, col_names = TRUE) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  arrange(date) |> 
  mutate(
    year = as.numeric(year),
    date = if_else(row_number() == 1, as_date("2020-01-20"), date),
    homes_powered = round((weight_tons * 500) / 30, digits = 0),
    sports_balls = round(sports_balls, digits = 0)
  )
```

## Cleaning `Professor Trash Wheel` Data
Next, similarly reading in and cleaning the data from the Excel file sheet `Professor Trash Wheel`:

* Specifying the sheet in the Excel file
* Using arguments in `read_excel`, omitting non-data entries like rows with figures and columns containing notes. As with the Mr. Trash Data, this is the first row and the `Homes` column
* Removing the last row, which is a sum count of column values and not dumpster-specific data, as well as any rows with no value for the `dumpster` value
* Creating a `homes_powered` for the approximate (whole) number of homes powered, based on the calculation described in the Homes powered note

```{r cleaning_professor}
professor = 
  read_excel("Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = cell_cols("A:L"), skip = 1, col_names = TRUE) |>
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    homes_powered = round((weight_tons * 500) / 30, digits = 0)
  )
```

## Cleaning `Gwynnda Trash Wheel` Data
Next, similarly reading in and cleaning the data from the Excel file sheet `Gwynnda Trash Wheel`:

* Specifying the sheet in the Excel file
* Using arguments in `read_excel`, omitting non-data entries like rows with figures and columns
* Removing the last row, which is a sum count of column values and not dumpster-specific data, as well as any rows with no value for the `dumpster` value
* Creating a `homes_powered` for the approximate (whole) number of homes powered, based on the calculation described in the Homes powered note

```{r cleaning_gywnnda}
gwynnda = 
  read_excel("Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = cell_cols("A:L"), skip = 1, col_names = TRUE) |>
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    homes_powered = round((weight_tons * 500) / 30, digits = 0)
  )
```

## Binding the Datasets

Now, adding a factor column to each dataset to identify the name of the source water-wheel (to help with identification post-merge). Then, binding the `professor` and `gwynnda` datasets together with the `mister` dataset to produce a single dataset. Finally, organizing the combined dataset to make it easier to understand by sorting it chronologically and re-arranging columns so that `sports_balls` is alongside the other types of trash, and `water_wheel` is moved to a more prominent location.

```{r joining_mister_professor_gwynnda}
mister = mutate(mister, water_wheel = "Mr. Trash Wheel")
professor = mutate(professor, water_wheel = "Professor Trash Wheel")
gwynnda = mutate(gwynnda, water_wheel = "Gwynnda Trash Wheel")

trash_wheels_tidy = 
  bind_rows(professor, gwynnda, mister) |> 
  mutate(
    water_wheel = as.factor(water_wheel)
  ) |> 
  arrange(date) |> 
  select(dumpster, water_wheel, month:volume_cubic_yards, homes_powered, everything())

```

The `trash_wheels_tidy` data set has `r nrow(trash_wheels_tidy)` observations and `r ncol(trash_wheels_tidy)` variables. It details the contents of dumpsters of trash collected by `r nlevels(pull(trash_wheels_tidy, var = water_wheel))` water-wheel vessels in Baltimore's Inner Harbor on specific dates between `r trash_wheels_tidy |> pull(year) |> min()` and `r trash_wheels_tidy |> pull(year) |> max()`. Of the `r nlevels(pull(trash_wheels_tidy, var = water_wheel))` wheels, the greatest amount of trash collected by a single wheel is `r filter(trash_wheels_tidy, water_wheel == "Mr. Trash Wheel") |> pull(weight_tons) |> sum()` tons by Mr. Trash Wheel. In comparison, Professor Trash Wheel has only removed `r filter(trash_wheels_tidy, water_wheel == "Professor Trash Wheel") |> pull(weight_tons) |> sum()` total tons of trash from the harbor.

In addition to the total weight and volume of trash collected, the dataset also tabulates counts of commonly-encountered debris. For example, in July 2021, Gwynnda Trash Wheel encountered `r format(filter(trash_wheels_tidy, water_wheel == "Gwynnda Trash Wheel", year == 2021, month == "July" ) |> pull(cigarette_butts) |> sum(), scientific = FALSE)` total cigarette butts. The good news is that those butts, in combination with the other trash she collected that month, is enough to power `r filter(trash_wheels_tidy, water_wheel == "Gwynnda Trash Wheel", year == 2021, month == "July" ) |> pull(homes_powered) |> sum()` homes.


