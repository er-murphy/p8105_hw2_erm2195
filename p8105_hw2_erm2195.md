P8105 Homework 2
================
2023-10-02

# Problem 1

Goal: merging the FiveThirtyEight `pols-month.csv`, `unemployment.csv`,
and `snp.csv` data into a single data frame using year and month as keys
across datasets.

## Loading Libraries

First, loading the `tidyverse` and `readxl` libraries for use throughout
the homework:

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

## Cleaning `pols-month` Data

Now, cleaning the data in `pols-month.csv`:

- Using separate() to break up the variable `mon` into integer variables
  `year`, `month`, and `day`
- Replacing month number with month name
- Creating a `president` variable taking values “gop” and “dem”
- Removing `prez_dem` and `prez_gop` variables
- Removing the `day` variable

``` r
pols = 
  read_csv("Data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-") |> 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day),
    president = if_else(prez_dem != 0 , "dem", "gop"),
    month = case_match(month,
      1 ~ "January",
      2 ~ "February",
      3 ~ "March",
      4 ~ "April",
      5 ~ "May",
      6 ~ "June",
      7 ~ "July",
      8 ~ "August",
      9 ~ "September",
      10 ~ "October",
      11 ~ "November",
      12 ~ "December")
  ) |> 
  select(-starts_with("prez"), -day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Cleaning `snp` Data

Second, cleaning the data in `snp.csv` using a similar process:

- Using separate() to break up the variable `date` into integer
  variables `year`, `month`, and `day`
- Converting the `year` variable into a 4 digit value
- Replacing month number with month name
- Reorganizing so that year and month are the leading columns
- Removing the `day` variable

``` r
snp = 
  read_csv("Data/snp.csv") |> 
  janitor::clean_names() |> 
  separate(date, into = c("month", "day", "year"), sep = "/") |> 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day),
    year = if_else(as.integer(year) < 24, as.integer(year) + 2000, as.integer(year) + 1900),
    month = case_match(month,
      1 ~ "January",
      2 ~ "February",
      3 ~ "March",
      4 ~ "April",
      5 ~ "May",
      6 ~ "June",
      7 ~ "July",
      8 ~ "August",
      9 ~ "September",
      10 ~ "October",
      11 ~ "November",
      12 ~ "December")
  ) |> 
  select(year, month, close)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Cleaning `unemployment` Data

Third, tidying the data in `unemployment.csv` so that it can be merged
with the other two datasets:

- Switch from “wide” to “long” format - turn months into a single
  column, and the value of existing `months` column into a column called
  `unemployment`
- Converting month names to capitalized full names to match the format
  of other datasets

``` r
unemployment = 
  read_csv("Data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(jan:dec, names_to = "month", values_to = "unemployment") |> 
  mutate(
    month = case_match(month,
    "jan" ~ "January",
    "feb" ~ "February",
    "mar" ~ "March",
    "apr" ~ "April",
    "may" ~ "May",
    "jun" ~ "June",
    "jul" ~ "July",
    "aug" ~ "August",
    "sep" ~ "September",
    "oct" ~ "October",
    "nov" ~ "November",
    "dec" ~ "December")
  )
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Merging the Data Sets

Joining the datasets by merging `snp` into `pols`, and then merging
`unemployment` into the result. The resulting dataset is called
`data_538`.

``` r
data_538 = left_join(pols, snp) |> 
  left_join(x = _, y = unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

``` r
str(data_538)
```

    ## tibble [822 × 11] (S3: tbl_df/tbl/data.frame)
    ##  $ year        : num [1:822] 1947 1947 1947 1947 1947 ...
    ##  $ month       : chr [1:822] "January" "February" "March" "April" ...
    ##  $ gov_gop     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_gop     : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
    ##  $ rep_gop     : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
    ##  $ gov_dem     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_dem     : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
    ##  $ rep_dem     : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
    ##  $ president   : chr [1:822] "dem" "dem" "dem" "dem" ...
    ##  $ close       : num [1:822] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ unemployment: num [1:822] NA NA NA NA NA NA NA NA NA NA ...

## Description of the Combined Data Set

The `pols` data set has 822 observations and 9 variables. It details the
party affiliation distribution (democrat or republican) for governors
and senators in a given year from 1947 to 2015. It also specifies the
political party of the president at that time. The `snp` data has 787
observations and 3 variables, and contains the closing value of the S&P
index on the associated date. The included dates range from 1950 to
2015. The `unemployment` data has 816 observations and 3 variables, and
contains the percentage of unemployment on the associated date, ranging
from years 1948 to 2015.

From the merged `538_data` data set we can see that in January from 1975
onward, in years with a democratic president, the average unemployment
rate was 6.57. For comparison, the average unemployment rate over the
same time period in which a republican was president was 6.47.

# Problem 2

## Cleaning `Mr. Trash Wheel` Data

First, reading in and cleaning the data from the Excel file sheet
`Mr. Trash Wheel`:

- Specifying the sheet in the Excel file
- Using arguments in `read_excel`, omitting the first row and `Homes`
  column, given that they contain notes and Excel-based functions
- Removing the last row, which is a sum count of column values and not
  dumpster-specific data, as well as any rows with no value for the
  `dumpster` value
- Converting the year variable to be of numeric type, to better match
  with the other two datasets coming up
- Fixing an issue where one row specifies a month and year of January
  2020, but the associated date is 1/20/1900 rather than 1/20/2020
- Creating a `homes_powered` for the approximate number of homes
  powered, based on the calculation described in the Homes powered note.
  Rounding this a whole number, which makes more intuitive sense than
  powering 0.27 of a home
- Rounding the `sports_balls` column so that it’s in whole numbers like
  the other trash count variables

Note: Rather than specifying the columns to import in the read_excel
statement, I think it makes more sense to import them all and then just
drop the Homes column specifically. That way, this code will still work
if additional columns are added in future years. But, doing it this way
as it seems like the right call, given that the question specified that
we should omit columns with non-data entries within the arguments of
`read_excel`.

``` r
mister = 
  read_excel("Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:M"), skip = 1, col_names = TRUE) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  arrange(date) |> 
  mutate(
    year = as.integer(year),
    date = if_else(row_number() == 1, as_date("2020-01-20"), date),
    homes_powered = round((weight_tons * 500) / 30, digits = 0),
    sports_balls = round(sports_balls, digits = 0)
  )
```

## Cleaning `Professor Trash Wheel` Data

Next, similarly reading in and cleaning the data from the Excel file
sheet `Professor Trash Wheel`:

- Specifying the sheet in the Excel file
- Using arguments in `read_excel`, omitting non-data entries like rows
  with figures and columns containing notes. As with the Mr. Trash Data,
  this is the first row and the `Homes` column
- Removing the last row, which is a sum count of column values and not
  dumpster-specific data, as well as any rows with no value for the
  `dumpster` value
- Creating a `homes_powered` for the approximate (whole) number of homes
  powered, based on the calculation described in the Homes powered note

``` r
professor = 
  read_excel("Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = cell_cols("A:L"), skip = 1, col_names = TRUE) |>
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    homes_powered = round((weight_tons * 500) / 30, digits = 0)
  )
```

## Cleaning `Gwynnda Trash Wheel` Data

Next, similarly reading in and cleaning the data from the Excel file
sheet `Gwynnda Trash Wheel`:

- Specifying the sheet in the Excel file
- Using arguments in `read_excel`, omitting non-data entries like rows
  with figures and columns
- Removing the last row, which is a sum count of column values and not
  dumpster-specific data, as well as any rows with no value for the
  `dumpster` value
- Creating a `homes_powered` for the approximate (whole) number of homes
  powered, based on the calculation described in the Homes powered note

``` r
gwynnda = 
  read_excel("Data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = cell_cols("A:L"), skip = 1, col_names = TRUE) |>
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    homes_powered = round((weight_tons * 500) / 30, digits = 0)
  )
```

## Binding the Datasets

Now, adding a factor column to each dataset to identify the name of the
source water-wheel (to help with identification post-merge). Then,
binding the `professor` and `gwynnda` datasets together with the
`mister` dataset to produce a single dataset. Finally, organizing the
combined dataset to make it easier to understand by sorting it
chronologically and re-arranging columns so that `sports_balls` is
alongside the other types of trash, and `water_wheel` is moved to a more
prominent location.

``` r
mister = mutate(mister, water_wheel = "Mr. Trash Wheel")
professor = mutate(professor, water_wheel = "Professor Trash Wheel")
gwynnda = mutate(gwynnda, water_wheel = "Gwynnda Trash Wheel")

trash_wheels_tidy = 
  bind_rows(professor, gwynnda, mister) |> 
  mutate(
    water_wheel = as.factor(water_wheel)
  ) |> 
  arrange(date) |> 
  select(dumpster, water_wheel, month:volume_cubic_yards, homes_powered, everything())
```

The `trash_wheels_tidy` data set has 845 observations and 15 variables.
It details the contents of dumpsters of trash collected by 3 water-wheel
vessels in Baltimore’s Inner Harbor on specific dates between 2014 and
2023. Of the 3 wheels, the greatest amount of trash collected by a
single wheel is 1875.1 tons by Mr. Trash Wheel. In comparison, Professor
Trash Wheel has only removed 216.26 total tons of trash from the harbor.

In addition to the total weight and volume of trash collected, the
dataset also includes counts of commonly-encountered debris. For
example, in July 2021, Gwynnda Trash Wheel encountered 16300 total
cigarette butts. The good news is that those butts, in combination with
the other trash she collected that month, is enough to power 136 homes.

# Problem 3

## Background and Data Collection

This problem uses data collected in an observational study to understand
the trajectory of Alzheimer’s disease (AD) biomarkers. Study
participants were free of Mild Cognitive Impairment (MCI), a stage
between the expected cognitive decline of normal aging and the more
serious decline of dementia, at the study baseline.

Basic demographic information were measured at the study baseline. The
study monitored the development of MCI and recorded the age of MCI onset
during the follow-up period, with the last visit marking the end of
follow-up. APOE4 is a variant of the apolipoprotein E gene,
significantly associated with a higher risk of developing Alzheimer’s
disease. The amyloid β 42/40 ratio holds significant promise for
diagnosing and predicting disease outcomes. This ratio undergoes changes
over time and has been linked to the manifestation of clinical symptoms
of Alzheimer’s disease.

## Cleaning `Baseline` Data

Importing, cleaning, and tidying the dataset of baseline demographics:

- Skipping the first line of the CSV, which detail the codes for each
  variable
- Renaming the `age_at_baseline` and `years_education` variables to more
  clearly describe their contents
- Converting the `id` and `years_education` variables to integers
- Converting the `age_at_baseline` and `age_at_onset` variables to
  numeric (not integers in order to preserve the months details)
- Converting the `sex` and `apoe4` variables to factors based on the
  described codes for their values
- Filtering out observations where the participant’s age of MCI onset is
  younger than age at baseline, as these individuals have MCI that
  pre-dates the start of the study (and therefore don’t meet the
  inclusion criteria)

``` r
baseline = 
  read_csv("Data/MCI_baseline.csv", skip = 1, na = ".") |> 
  janitor::clean_names() |> 
  rename(age_at_baseline = current_age, years_education = education) |> 
  mutate (
    id = as.integer(id),
    age_at_baseline = as.numeric(age_at_baseline),
    sex = as.factor(
      case_match(sex,
        1 ~ "male", 
        0 ~ "female")),
    years_education = as.integer(years_education),
    apoe4 = as.factor(
      case_match(apoe4,
        1 ~ "carrier", 
        0 ~ "non-carrier")),  
    age_at_onset = as.numeric(age_at_onset)
  ) |> 
  filter((age_at_onset >= age_at_baseline) | is.na(age_at_onset))
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (6): ID, Current Age, Sex, Education, apoe4, Age at onset
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
str(baseline)
```

    ## tibble [480 × 6] (S3: tbl_df/tbl/data.frame)
    ##  $ id             : int [1:480] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ age_at_baseline: num [1:480] 63.1 65.6 62.5 69.8 66 62.5 66.5 67.2 66.7 64.1 ...
    ##  $ sex            : Factor w/ 2 levels "female","male": 1 1 2 1 2 2 2 1 1 1 ...
    ##  $ years_education: int [1:480] 16 20 16 16 16 16 18 18 16 18 ...
    ##  $ apoe4          : Factor w/ 2 levels "carrier","non-carrier": 1 1 1 2 2 2 2 2 2 2 ...
    ##  $ age_at_onset   : num [1:480] NA NA 66.8 NA 68.7 NA 74 NA NA NA ...

Discuss important steps in the import process and relevant features of
the dataset. How many participants were recruited, and of these how many
develop MCI? What is the average baseline age? What proportion of women
in the study are APOE4 carriers?
